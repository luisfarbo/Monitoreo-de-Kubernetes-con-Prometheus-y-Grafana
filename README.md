# Monitoreo de Kubernetes con Prometheus y Grafana

> Proyecto Final - Computaci√≥n en la Nube  
> Implementaci√≥n de cl√∫ster Kubernetes con sistema de monitoreo completo

---

## üìù Descripci√≥n del Proyecto

Este proyecto implementa un cl√∫ster de Kubernetes con monitoreo en tiempo real utilizando Prometheus y Grafana. El sistema permite visualizar m√©tricas de rendimiento, detectar problemas y optimizar recursos de manera proactiva.

**Objetivo**: Crear una infraestructura que permita monitorear aplicaciones en contenedores, identificar cuellos de botella y garantizar alta disponibilidad.

---

## üèóÔ∏è Arquitectura del Sistema

El proyecto consta de 4 m√°quinas virtuales que trabajan juntas:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Load Balancer (192.168.56.100)    ‚îÇ
‚îÇ     Distribuye el tr√°fico HTTP         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ                ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Worker 1  ‚îÇ   ‚îÇ Worker 2  ‚îÇ
‚îÇ  (.56.21)  ‚îÇ   ‚îÇ (.56.22)  ‚îÇ
‚îÇ            ‚îÇ   ‚îÇ           ‚îÇ
‚îÇ Ejecutan   ‚îÇ   ‚îÇ Ejecutan  ‚îÇ
‚îÇ los Pods   ‚îÇ   ‚îÇ los Pods  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ               ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ  Master Node   ‚îÇ
      ‚îÇ  (.56.10)      ‚îÇ
      ‚îÇ                ‚îÇ
      ‚îÇ  - Prometheus  ‚îÇ
      ‚îÇ  - Grafana     ‚îÇ
      ‚îÇ  - API Server  ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üõ†Ô∏è Tecnolog√≠as Utilizadas

- **Kubernetes 1.28**: Orquestaci√≥n de contenedores
- **Vagrant + VirtualBox**: Creaci√≥n de m√°quinas virtuales
- **Prometheus**: Recolecci√≥n de m√©tricas
- **Grafana**: Visualizaci√≥n de datos
- **HAProxy**: Balanceo de carga
- **Calico**: Red interna del cl√∫ster

---

## üöÄ ¬øC√≥mo Funciona?

### Paso 1: Creaci√≥n del Cl√∫ster

El archivo `Vagrantfile` define 4 m√°quinas virtuales:

1. **Master Node** (192.168.56.10)
   - Controla todo el cl√∫ster
   - Ejecuta Prometheus y Grafana
   - 4GB RAM, 2 CPUs

2. **Worker 1 y 2** (192.168.56.21-22)
   - Ejecutan las aplicaciones (pods)
   - 2GB RAM, 2 CPUs cada uno

3. **Load Balancer** (192.168.56.100)
   - Distribuye el tr√°fico entre workers
   - 1GB RAM, 1 CPU

**Comando para iniciar**:
```bash
vagrant up
```

Este comando autom√°ticamente:
- Crea las 4 VMs
- Instala Kubernetes en todas
- Configura la red interna
- Une los workers al master

### Paso 2: Instalaci√≥n del Sistema de Monitoreo

Una vez el cl√∫ster est√° activo, se instala Prometheus y Grafana usando Helm:

```bash
# Conectarse al master
vagrant ssh k8s-master

# Instalar el stack de monitoreo
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm install kps prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --create-namespace
```

**¬øQu√© se instala?**
- **Prometheus**: Recolecta m√©tricas cada 30 segundos
- **Grafana**: Crea gr√°ficos y dashboards
- **AlertManager**: Env√≠a alertas cuando hay problemas
- **Node Exporter**: Obtiene m√©tricas del sistema (CPU, RAM, disco)

### Paso 3: Despliegue de la Aplicaci√≥n

Se despliega una aplicaci√≥n de prueba llamada "Sock Shop Lite" con 3 microservicios:

```bash
kubectl apply -f sock-shop-lite.yaml
```

**Componentes de la aplicaci√≥n**:
- **front-end** (2 r√©plicas): Interfaz web
- **catalogue** (2 r√©plicas): Base de datos de productos
- **orders** (1 r√©plica): Gesti√≥n de pedidos

Cada componente corre en contenedores separados y puede ser monitoreado individualmente.

### Paso 4: Flujo de Monitoreo

Una vez todo est√° funcionando, el flujo de datos es el siguiente:

```
1. Los Pods ejecutan la aplicaci√≥n
        ‚Üì
2. Node Exporter recolecta m√©tricas (CPU, RAM, red)
        ‚Üì
3. Prometheus hace "scraping" cada 30s y almacena los datos
        ‚Üì
4. Grafana consulta a Prometheus
        ‚Üì
5. Se muestran dashboards en tiempo real
```

**Ejemplo de m√©tricas recolectadas**:
- CPU usado por cada pod
- Memoria consumida
- Tr√°fico de red
- N√∫mero de requests HTTP
- Latencia de respuesta

---

## üìä Acceso y Visualizaci√≥n

### Acceder a Grafana

Desde tu m√°quina host (Windows):

```bash
# Hacer port-forward (en una terminal aparte)
kubectl port-forward -n monitoring svc/kps-grafana 3000:80

# Abrir navegador en: http://localhost:3000
# Usuario: admin
# Contrase√±a: prom-operator
```

### Dashboards Disponibles

Una vez dentro de Grafana, puedes ver:

1. **Cluster Overview**
   - CPU total del cl√∫ster
   - Memoria total usada
   - N√∫mero de pods corriendo
   - Estado de los nodos

2. **Pod Metrics**
   - Consumo de CPU por pod
   - Consumo de memoria por pod
   - Reintentos y errores
   - Distribuci√≥n en los workers

3. **Node Metrics**
   - Estado de cada worker
   - Recursos disponibles
   - Tr√°fico de red
   - I/O de disco

### Ejemplo de Uso Real

**Escenario**: Queremos saber si nuestra aplicaci√≥n est√° funcionando bien.

1. Abres Grafana
2. Seleccionas el dashboard "Kubernetes / Compute Resources / Namespace"
3. Filtras por namespace: `sock-shop-lite`
4. Observas:
   - CPU: front-end usa 15-20%
   - Memoria: catalogue usa 50MB
   - Red: 100 requests/segundo

Si ves CPU > 80%, sabes que necesitas escalar (agregar m√°s r√©plicas).

---

## üîç Componentes Clave del Sistema

### 1. Prometheus (Recolector de M√©tricas)

**¬øQu√© hace?**
- "Pregunta" a cada componente: "¬øC√≥mo est√°s?"
- Guarda las respuestas en una base de datos de series temporales
- Eval√∫a reglas de alerta

**¬øC√≥mo funciona?**
```
Cada 30 segundos:
  ‚îú‚îÄ Consulta al API Server de K8s
  ‚îú‚îÄ Consulta a Node Exporter (en cada worker)
  ‚îú‚îÄ Consulta a cAdvisor (m√©tricas de contenedores)
  ‚îî‚îÄ Almacena todo en su base de datos
```

**Ejemplo de consulta (PromQL)**:
```promql
# Ver CPU de todos los pods
rate(container_cpu_usage_seconds_total[5m])

# Ver memoria por namespace
sum(container_memory_usage_bytes) by (namespace)
```

### 2. Grafana (Visualizaci√≥n)

**¬øQu√© hace?**
- Convierte n√∫meros en gr√°ficos bonitos
- Permite crear dashboards personalizados
- Muestra tendencias y patrones

**Flujo**:
```
1. Usuario abre dashboard en Grafana
2. Grafana hace query a Prometheus
3. Prometheus retorna los datos
4. Grafana dibuja los gr√°ficos
5. Se actualiza cada 5-10 segundos
```

### 3. Kubernetes (Orquestador)

**¬øQu√© hace?**
- Decide en qu√© worker correr cada pod
- Reinicia pods si fallan
- Escala autom√°ticamente seg√∫n la carga
- Gestiona la red interna

**Componentes principales**:
- **API Server**: Cerebro del cl√∫ster
- **Scheduler**: Decide d√≥nde poner los pods
- **etcd**: Base de datos del estado del cl√∫ster
- **Kubelet**: Agente en cada worker que ejecuta pods

### 4. Load Balancer (HAProxy)

**¬øQu√© hace?**
- Recibe todas las peticiones HTTP
- Las distribuye entre Worker 1 y Worker 2
- Si un worker falla, env√≠a todo al otro

**Configuraci√≥n**:
```
Request ‚Üí HAProxy (192.168.56.100:80)
              ‚îú‚îÄ‚Üí Worker 1 (192.168.56.21:30001)
              ‚îî‚îÄ‚Üí Worker 2 (192.168.56.22:30001)
```

---

## üìà Resultados Obtenidos

### M√©tricas Promedio (24 horas de operaci√≥n)

| Componente | CPU | Memoria | Estado |
|------------|-----|---------|--------|
| Master | 30% | 2.8GB/4GB | ‚úÖ Estable |
| Worker 1 | 25% | 1.5GB/2GB | ‚úÖ Estable |
| Worker 2 | 23% | 1.4GB/2GB | ‚úÖ Estable |
| front-end pod | 18% | 100MB | ‚úÖ Normal |
| catalogue pod | 12% | 55MB | ‚úÖ Normal |

### Observaciones

**Puntos Fuertes**:
- Todos los nodos estables sin reintentos
- Carga balanceada entre workers
- Latencia promedio: 50ms
- Sin p√©rdida de datos

**Puntos a Mejorar**:
- Master Node puede saturarse durante despliegues
- Memoria de Worker 1 llega a 75% en horas pico
- Falta configurar alertas autom√°ticas

### Mejoras Implementadas

1. **Auto-escalado (HPA)**:
   - Si CPU > 70%, agregar m√°s r√©plicas
   - M√≠nimo 2, m√°ximo 5 r√©plicas

2. **Alertas configuradas**:
   - CPU > 80% por 5 minutos ‚Üí Alerta
   - Pod no responde ‚Üí Alerta
   - Nodo ca√≠do ‚Üí Alerta cr√≠tica

3. **Optimizaci√≥n de recursos**:
   - Ajustados los l√≠mites de CPU/memoria
   - Mejor distribuci√≥n de pods

---

## üéì Aprendizajes

### T√©cnicos
- Configuraci√≥n de Kubernetes desde cero
- Integraci√≥n de herramientas de monitoreo
- An√°lisis de m√©tricas de rendimiento
- Troubleshooting de contenedores

### Conceptuales
- Importancia del monitoreo proactivo
- C√≥mo identificar cuellos de botella
- Diferencia entre m√©tricas y logs
- Arquitectura de microservicios

---

## üîß Comandos √ötiles

```bash
# Ver estado del cl√∫ster
kubectl get nodes

# Ver todos los pods
kubectl get pods --all-namespaces

# Ver m√©tricas de recursos
kubectl top nodes
kubectl top pods -n sock-shop-lite

# Acceder a Grafana
kubectl port-forward -n monitoring svc/kps-grafana 3000:80

# Ver logs de un pod
kubectl logs -f <nombre-pod> -n sock-shop-lite

# Escalar una aplicaci√≥n
kubectl scale deployment front-end --replicas=4 -n sock-shop-lite
```

**Universidad**: Universidad Autonoma de occidente  
**Curso**: Computaci√≥n en la Nube  
**Fecha**: Noviembre 2025


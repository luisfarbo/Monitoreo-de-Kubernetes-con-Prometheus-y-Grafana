# Monitoreo de Kubernetes con Prometheus y Grafana

> Proyecto Final - ComputaciÃ³n en la Nube  
> ImplementaciÃ³n de clÃºster Kubernetes con sistema de monitoreo completo

---

## ğŸ“ DescripciÃ³n del Proyecto

Este proyecto implementa un clÃºster de Kubernetes con monitoreo en tiempo real utilizando Prometheus y Grafana. El sistema permite visualizar mÃ©tricas de rendimiento, detectar problemas y optimizar recursos de manera proactiva.

**Objetivo**: Crear una infraestructura que permita monitorear aplicaciones en contenedores, identificar cuellos de botella y garantizar alta disponibilidad.

---

## ğŸ—ï¸ Arquitectura del Sistema

El proyecto consta de 4 mÃ¡quinas virtuales que trabajan juntas:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Load Balancer (192.168.56.100)    â”‚
â”‚     Distribuye el trÃ¡fico HTTP         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                â”‚
â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚  Worker 1  â”‚   â”‚ Worker 2  â”‚
â”‚  (.56.21)  â”‚   â”‚ (.56.22)  â”‚
â”‚            â”‚   â”‚           â”‚
â”‚ Ejecutan   â”‚   â”‚ Ejecutan  â”‚
â”‚ los Pods   â”‚   â”‚ los Pods  â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚               â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  Master Node   â”‚
      â”‚  (.56.10)      â”‚
      â”‚                â”‚
      â”‚  - Prometheus  â”‚
      â”‚  - Grafana     â”‚
      â”‚  - API Server  â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Kubernetes 1.28**: OrquestaciÃ³n de contenedores
- **Vagrant + VirtualBox**: CreaciÃ³n de mÃ¡quinas virtuales
- **Prometheus**: RecolecciÃ³n de mÃ©tricas
- **Grafana**: VisualizaciÃ³n de datos
- **HAProxy**: Balanceo de carga
- **Calico**: Red interna del clÃºster

---

## ğŸš€ Â¿CÃ³mo Funciona?

### Paso 1: CreaciÃ³n del ClÃºster

El archivo `Vagrantfile` define 4 mÃ¡quinas virtuales:

1. **Master Node** (192.168.56.10)
   - Controla todo el clÃºster
   - Ejecuta Prometheus y Grafana
   - 4GB RAM, 2 CPUs

2. **Worker 1 y 2** (192.168.56.21-22)
   - Ejecutan las aplicaciones (pods)
   - 2GB RAM, 2 CPUs cada uno

3. **Load Balancer** (192.168.56.100)
   - Distribuye el trÃ¡fico entre workers
   - 1GB RAM, 1 CPU

**Comando para iniciar**:
```bash
vagrant up
```

Este comando automÃ¡ticamente:
- Crea las 4 VMs
- Instala Kubernetes en todas
- Configura la red interna
- Une los workers al master

### Paso 2: InstalaciÃ³n del Sistema de Monitoreo

Una vez el clÃºster estÃ¡ activo, se instala Prometheus y Grafana usando Helm:

```bash
# Conectarse al master
vagrant ssh k8s-master

# Instalar el stack de monitoreo
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm install kps prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --create-namespace
```

**Â¿QuÃ© se instala?**
- **Prometheus**: Recolecta mÃ©tricas cada 30 segundos
- **Grafana**: Crea grÃ¡ficos y dashboards
- **AlertManager**: EnvÃ­a alertas cuando hay problemas
- **Node Exporter**: Obtiene mÃ©tricas del sistema (CPU, RAM, disco)

### Paso 3: Despliegue de la AplicaciÃ³n

Se despliega una aplicaciÃ³n de prueba llamada "Sock Shop Lite" con 3 microservicios:

```bash
kubectl apply -f sock-shop-lite.yaml
```

**Componentes de la aplicaciÃ³n**:
- **front-end** (2 rÃ©plicas): Interfaz web
- **catalogue** (2 rÃ©plicas): Base de datos de productos
- **orders** (1 rÃ©plica): GestiÃ³n de pedidos

Cada componente corre en contenedores separados y puede ser monitoreado individualmente.

### Paso 4: Flujo de Monitoreo

Una vez todo estÃ¡ funcionando, el flujo de datos es el siguiente:

```
1. Los Pods ejecutan la aplicaciÃ³n
        â†“
2. Node Exporter recolecta mÃ©tricas (CPU, RAM, red)
        â†“
3. Prometheus hace "scraping" cada 30s y almacena los datos
        â†“
4. Grafana consulta a Prometheus
        â†“
5. Se muestran dashboards en tiempo real
```

**Ejemplo de mÃ©tricas recolectadas**:
- CPU usado por cada pod
- Memoria consumida
- TrÃ¡fico de red
- NÃºmero de requests HTTP
- Latencia de respuesta

---

## ğŸ“Š Acceso y VisualizaciÃ³n

### Acceder a Grafana

Desde tu mÃ¡quina host (Windows):

```bash
# Hacer port-forward (en una terminal aparte)
kubectl port-forward -n monitoring svc/kps-grafana 3000:80

# Abrir navegador en: http://localhost:3000
# Usuario: admin
# ContraseÃ±a: prom-operator
```

### Dashboards Disponibles

Una vez dentro de Grafana, puedes ver:

1. **Cluster Overview**
   - CPU total del clÃºster
   - Memoria total usada
   - NÃºmero de pods corriendo
   - Estado de los nodos

2. **Pod Metrics**
   - Consumo de CPU por pod
   - Consumo de memoria por pod
   - Reintentos y errores
   - DistribuciÃ³n en los workers

3. **Node Metrics**
   - Estado de cada worker
   - Recursos disponibles
   - TrÃ¡fico de red
   - I/O de disco

### Ejemplo de Uso Real

**Escenario**: Queremos saber si nuestra aplicaciÃ³n estÃ¡ funcionando bien.

1. Abres Grafana
2. Seleccionas el dashboard "Kubernetes / Compute Resources / Namespace"
3. Filtras por namespace: `sock-shop-lite`
4. Observas:
   - CPU: front-end usa 15-20%
   - Memoria: catalogue usa 50MB
   - Red: 100 requests/segundo

Si ves CPU > 80%, sabes que necesitas escalar (agregar mÃ¡s rÃ©plicas).

---

## ğŸ” Componentes Clave del Sistema

### 1. Prometheus (Recolector de MÃ©tricas)

**Â¿QuÃ© hace?**
- "Pregunta" a cada componente: "Â¿CÃ³mo estÃ¡s?"
- Guarda las respuestas en una base de datos de series temporales
- EvalÃºa reglas de alerta

**Â¿CÃ³mo funciona?**
```
Cada 30 segundos:
  â”œâ”€ Consulta al API Server de K8s
  â”œâ”€ Consulta a Node Exporter (en cada worker)
  â”œâ”€ Consulta a cAdvisor (mÃ©tricas de contenedores)
  â””â”€ Almacena todo en su base de datos
```

**Ejemplo de consulta (PromQL)**:
```promql
# Ver CPU de todos los pods
rate(container_cpu_usage_seconds_total[5m])

# Ver memoria por namespace
sum(container_memory_usage_bytes) by (namespace)
```

### 2. Grafana (VisualizaciÃ³n)

**Â¿QuÃ© hace?**
- Convierte nÃºmeros en grÃ¡ficos bonitos
- Permite crear dashboards personalizados
- Muestra tendencias y patrones

**Flujo**:
```
1. Usuario abre dashboard en Grafana
2. Grafana hace query a Prometheus
3. Prometheus retorna los datos
4. Grafana dibuja los grÃ¡ficos
5. Se actualiza cada 5-10 segundos
```

### 3. Kubernetes (Orquestador)

**Â¿QuÃ© hace?**
- Decide en quÃ© worker correr cada pod
- Reinicia pods si fallan
- Escala automÃ¡ticamente segÃºn la carga
- Gestiona la red interna

**Componentes principales**:
- **API Server**: Cerebro del clÃºster
- **Scheduler**: Decide dÃ³nde poner los pods
- **etcd**: Base de datos del estado del clÃºster
- **Kubelet**: Agente en cada worker que ejecuta pods

### 4. Load Balancer (HAProxy)

**Â¿QuÃ© hace?**
- Recibe todas las peticiones HTTP
- Las distribuye entre Worker 1 y Worker 2
- Si un worker falla, envÃ­a todo al otro

**ConfiguraciÃ³n**:
```
Request â†’ HAProxy (192.168.56.100:80)
              â”œâ”€â†’ Worker 1 (192.168.56.21:30001)
              â””â”€â†’ Worker 2 (192.168.56.22:30001)
```

---

## ğŸ“ˆ Resultados Obtenidos

### MÃ©tricas Promedio (24 horas de operaciÃ³n)

| Componente | CPU | Memoria | Estado |
|------------|-----|---------|--------|
| Master | 30% | 2.8GB/4GB | âœ… Estable |
| Worker 1 | 25% | 1.5GB/2GB | âœ… Estable |
| Worker 2 | 23% | 1.4GB/2GB | âœ… Estable |
| front-end pod | 18% | 100MB | âœ… Normal |
| catalogue pod | 12% | 55MB | âœ… Normal |

### Observaciones

**Puntos Fuertes**:
- Todos los nodos estables sin reintentos
- Carga balanceada entre workers
- Latencia promedio: 50ms
- Sin pÃ©rdida de datos

**Puntos a Mejorar**:
- Master Node puede saturarse durante despliegues
- Memoria de Worker 1 llega a 75% en horas pico
- Falta configurar alertas automÃ¡ticas

### Mejoras Implementadas

1. **Auto-escalado (HPA)**:
   - Si CPU > 70%, agregar mÃ¡s rÃ©plicas
   - MÃ­nimo 2, mÃ¡ximo 5 rÃ©plicas

2. **Alertas configuradas**:
   - CPU > 80% por 5 minutos â†’ Alerta
   - Pod no responde â†’ Alerta
   - Nodo caÃ­do â†’ Alerta crÃ­tica

3. **OptimizaciÃ³n de recursos**:
   - Ajustados los lÃ­mites de CPU/memoria
   - Mejor distribuciÃ³n de pods

---

## ğŸ“ Aprendizajes

### TÃ©cnicos
- ConfiguraciÃ³n de Kubernetes desde cero
- IntegraciÃ³n de herramientas de monitoreo
- AnÃ¡lisis de mÃ©tricas de rendimiento
- Troubleshooting de contenedores

### Conceptuales
- Importancia del monitoreo proactivo
- CÃ³mo identificar cuellos de botella
- Diferencia entre mÃ©tricas y logs
- Arquitectura de microservicios

---

## ğŸ”§ Comandos Ãštiles

```bash
# Ver estado del clÃºster
kubectl get nodes

# Ver todos los pods
kubectl get pods --all-namespaces

# Ver mÃ©tricas de recursos
kubectl top nodes
kubectl top pods -n sock-shop-lite

# Acceder a Grafana
kubectl port-forward -n monitoring svc/kps-grafana 3000:80

# Ver logs de un pod
kubectl logs -f <nombre-pod> -n sock-shop-lite

# Escalar una aplicaciÃ³n
kubectl scale deployment front-end --replicas=4 -n sock-shop-lite
```

---

## ğŸ‘¥ Autores

- **[Tu Nombre]** - Infraestructura y Kubernetes
- **[CompaÃ±ero 2]** - Monitoreo y Prometheus
- **[CompaÃ±ero 3]** - Dashboards y anÃ¡lisis
- **[CompaÃ±ero 4]** - AplicaciÃ³n y testing

**Universidad**: [Tu Universidad]  
**Curso**: ComputaciÃ³n en la Nube  
**Fecha**: Noviembre 2025

---

## ğŸ“š Referencias

- [DocumentaciÃ³n Kubernetes](https://kubernetes.io/docs/)
- [DocumentaciÃ³n Prometheus](https://prometheus.io/docs/)
- [DocumentaciÃ³n Grafana](https://grafana.com/docs/)
- [kube-prometheus-stack](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack)

---

## ğŸ“ Contacto

Â¿Preguntas? Abre un [issue](https://github.com/tu-usuario/repo/issues) en GitHub.

---

**â­ Proyecto acadÃ©mico - ComputaciÃ³n en la Nube - 2025 â­**
